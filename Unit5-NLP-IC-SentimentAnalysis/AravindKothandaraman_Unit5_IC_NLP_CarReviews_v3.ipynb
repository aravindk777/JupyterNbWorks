{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "-sXQv02x7Rs3",
    "UMIuLJIi7Wf1",
    "Waty-esn7fi3",
    "dDxQeXS-9q74"
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5cae758cf43a4e8fa7e02a8a2f25dfad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9a130a1a243d4291a1a8c920e8737242",
       "IPY_MODEL_0e41926a2993474a83067d7a87e8bc0a",
       "IPY_MODEL_96c6bf4a11a142d5896a11f9669280ba"
      ],
      "layout": "IPY_MODEL_84d9b665f16849138e40643c936adb3a"
     }
    },
    "9a130a1a243d4291a1a8c920e8737242": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf6a8708619d42d2b650cf68ddc41aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_e156cbf154ac4647adcc202b70655259",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "0e41926a2993474a83067d7a87e8bc0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_deed6951a3ae448fb3ff6c3edfcbb9be",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f62a1f757aa3461bbc26531630769745",
      "value": 48
     }
    },
    "96c6bf4a11a142d5896a11f9669280ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a77173078e114ff48b393ba1d5f37b88",
      "placeholder": "​",
      "style": "IPY_MODEL_7b5c947189364d388c33705537124f7e",
      "value": " 48.0/48.0 [00:00&lt;00:00, 1.34kB/s]"
     }
    },
    "84d9b665f16849138e40643c936adb3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf6a8708619d42d2b650cf68ddc41aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e156cbf154ac4647adcc202b70655259": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "deed6951a3ae448fb3ff6c3edfcbb9be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f62a1f757aa3461bbc26531630769745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a77173078e114ff48b393ba1d5f37b88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b5c947189364d388c33705537124f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee540ac34a1a47b7a56b4c14a2342982": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9cd26aebe0f4b74b1e93dfe8a741a0d",
       "IPY_MODEL_15a7597713ce466c962a34809cf2b646",
       "IPY_MODEL_569e4c4df6d246e8a1584e9de1fdaf52"
      ],
      "layout": "IPY_MODEL_8bbd1cd1097747b7ba1da78b5ad3c87d"
     }
    },
    "c9cd26aebe0f4b74b1e93dfe8a741a0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e604c25daef4ed59fee0c17cb8f2114",
      "placeholder": "​",
      "style": "IPY_MODEL_e0669a3f53c148cd9c76860484ef2eb3",
      "value": "vocab.txt: 100%"
     }
    },
    "15a7597713ce466c962a34809cf2b646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e82e75cdedc49d9ba26ed371afbd150",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_329079f983df483aaec7e856f69b3584",
      "value": 231508
     }
    },
    "569e4c4df6d246e8a1584e9de1fdaf52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79cd8bcf772a41ca9f0532033c9d58de",
      "placeholder": "​",
      "style": "IPY_MODEL_1db267536a0d41e5a9a4d67d98690eac",
      "value": " 232k/232k [00:00&lt;00:00, 1.03MB/s]"
     }
    },
    "8bbd1cd1097747b7ba1da78b5ad3c87d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e604c25daef4ed59fee0c17cb8f2114": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0669a3f53c148cd9c76860484ef2eb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e82e75cdedc49d9ba26ed371afbd150": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "329079f983df483aaec7e856f69b3584": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79cd8bcf772a41ca9f0532033c9d58de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1db267536a0d41e5a9a4d67d98690eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc0f862d7e7942b7912329f58d701a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a452cebd66247bb9b5680e4c7a39248",
       "IPY_MODEL_80343f0b8905457abfa00b1733f2a7b5",
       "IPY_MODEL_7faca56a24e245c7ba34f54e89ba2e90"
      ],
      "layout": "IPY_MODEL_4120070166604abd83ba1736139b2d5d"
     }
    },
    "2a452cebd66247bb9b5680e4c7a39248": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_190a3b8ea9cf43b697b4d64d1b18de90",
      "placeholder": "​",
      "style": "IPY_MODEL_c7aea070847d4f25949d8ab718ebde8c",
      "value": "tokenizer.json: 100%"
     }
    },
    "80343f0b8905457abfa00b1733f2a7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43d471525f944c23901b051c8568cb57",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a74899fb027b4a72adb7845f7c93dd7f",
      "value": 466062
     }
    },
    "7faca56a24e245c7ba34f54e89ba2e90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18bc6125404b44d88dabe400046695c5",
      "placeholder": "​",
      "style": "IPY_MODEL_75f5ae56eb334772965a5930e86bfec3",
      "value": " 466k/466k [00:00&lt;00:00, 1.01MB/s]"
     }
    },
    "4120070166604abd83ba1736139b2d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "190a3b8ea9cf43b697b4d64d1b18de90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7aea070847d4f25949d8ab718ebde8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43d471525f944c23901b051c8568cb57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a74899fb027b4a72adb7845f7c93dd7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "18bc6125404b44d88dabe400046695c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75f5ae56eb334772965a5930e86bfec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "186f6362e5a9404980ffb41af7590e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc3b8632ebbe4e0d90482fd9d8cbf3bd",
       "IPY_MODEL_c6993608a5e64fa380f1a856baa30c48",
       "IPY_MODEL_54881e1b21c24951b8e83d85687a825d"
      ],
      "layout": "IPY_MODEL_1163a340d9384a6ea02b4d7edf2fa121"
     }
    },
    "bc3b8632ebbe4e0d90482fd9d8cbf3bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cb5e33a5f344a86905b07f421cb02b5",
      "placeholder": "​",
      "style": "IPY_MODEL_038d2a42ef7a4ac1b8f834c6875d3c41",
      "value": "config.json: 100%"
     }
    },
    "c6993608a5e64fa380f1a856baa30c48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43cda19902664853a9efb826cbc6de78",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68d72d7df916461281c59ff927f495bf",
      "value": 570
     }
    },
    "54881e1b21c24951b8e83d85687a825d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4331e9241b04383b6864fb681b63f8b",
      "placeholder": "​",
      "style": "IPY_MODEL_d8d804be4bcd40a4aa7c071e9b95bc6e",
      "value": " 570/570 [00:00&lt;00:00, 72.2kB/s]"
     }
    },
    "1163a340d9384a6ea02b4d7edf2fa121": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cb5e33a5f344a86905b07f421cb02b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "038d2a42ef7a4ac1b8f834c6875d3c41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43cda19902664853a9efb826cbc6de78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68d72d7df916461281c59ff927f495bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4331e9241b04383b6864fb681b63f8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8d804be4bcd40a4aa7c071e9b95bc6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Unit 5 - Incremental Capstone - NLP\n",
    "\n",
    "### Aravind Kothandaraman\n",
    "2509 batch\n",
    "\n",
    "#### This is being worked upon using the \"car reviews\" zip file dataset provided in the IC dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Install and Import necessary packages"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:49:58.532848Z",
     "start_time": "2026-02-04T05:49:56.576732400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install required packages (only once; skip if already installed)\n",
    "# NLTK (Natural Language Toolkit) is a Python library for teaching and working with human language data, offering tools for tokenization, tagging, and parsing.\n",
    "!pip install nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from nltk) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from nltk) (4.67.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:50:07.493580Z",
     "start_time": "2026-02-04T05:50:02.456415500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the necessary packages\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:50:08.292257Z",
     "start_time": "2026-02-04T05:50:08.101452500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')  # Sentence tokenizer\n",
    "nltk.download('words')  # English word list\n",
    "nltk.download('stopwords')  # Common stopwords\n",
    "nltk.download('wordnet')  # WordNet lexical database\n",
    "nltk.download('punkt_tab') # Download punkt_tab resource"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:50:10.726359800Z",
     "start_time": "2026-02-04T05:50:10.720456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import WordNet, a lexical database used for lemmatization and semantic analysis\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Import a list of common English stopwords (e.g., \"the\", \"and\", \"is\") used for filtering out non-informative words\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:50:11.819192100Z",
     "start_time": "2026-02-04T05:50:11.807656300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Load the \"reviews.zip\" dataset, extract the dataset file and cleanse/preprocess the text data.\n",
    "\n",
    "## *Task-1 work from IC*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract the dataset from the zip file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:25.534898400Z",
     "start_time": "2026-02-03T01:39:25.484186100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_zip = 'review.zip'\n",
    "import zipfile\n",
    "with zipfile.ZipFile(source_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the data and review"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:19:36.348010400Z",
     "start_time": "2026-02-04T06:19:36.336287900Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = 'Car_Reviews_Database.csv'",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:19:37.918133400Z",
     "start_time": "2026-02-04T06:19:37.900249100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tried with the `utf-8` encoding, but it didnt work.\n",
    "# attempted with `latin1` encoding and it worked.\n",
    "car_reviews_df = pd.read_csv(dataset, encoding=\"latin1\")"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:19:51.368685Z",
     "start_time": "2026-02-04T06:19:51.329782Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Year    278 non-null    int64 \n",
      " 1   Model   278 non-null    object\n",
      " 2   Review  234 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:19:55.478013300Z",
     "start_time": "2026-02-04T06:19:55.427564400Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df.head(10)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Year Model                                              Review\n",
       "0  2009  Honda  Although arguably the first-generation Insight...\n",
       "1  2009  Honda  2009 Honda Accord EX-L 4  : This car is very c...\n",
       "2  2010  Honda  I have owed and driven Honda products for 20 y...\n",
       "3  2010  Honda  Honda Accord Euro L : The seats are average, b...\n",
       "4  2011  Honda   Honda HR-V: Continuous variable transmission ...\n",
       "5  2011  Honda  Not much has changed with the historically sec...\n",
       "6  2012  Honda  Honda Ballade 150 1.5: This is the most reliab...\n",
       "7  2012  Honda  Ride quality is top-notch, though communicatio...\n",
       "8  2013  Honda  Honda Jazz Hybrid 1.4 : This is my second Hond...\n",
       "9  2013  Honda  The CR-V's voluminous cargo area, quick-foldin..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Although arguably the first-generation Insight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2009 Honda Accord EX-L 4  : This car is very c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Honda</td>\n",
       "      <td>I have owed and driven Honda products for 20 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda Accord Euro L : The seats are average, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda HR-V: Continuous variable transmission ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Not much has changed with the historically sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda Ballade 150 1.5: This is the most reliab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Ride quality is top-notch, though communicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda Jazz Hybrid 1.4 : This is my second Hond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>Honda</td>\n",
       "      <td>The CR-V's voluminous cargo area, quick-foldin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing - Rename columns for easier handling"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:01.258820500Z",
     "start_time": "2026-02-04T06:20:01.243004600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rename columns for easier handling\n",
    "car_reviews_df.rename(columns={'Review': 'review_text', 'Model ': 'car_make', 'Year': 'car_year'}, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:02.342612700Z",
     "start_time": "2026-02-04T06:20:02.305776300Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df['review_text'].head(10)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Although arguably the first-generation Insight...\n",
       "1    2009 Honda Accord EX-L 4  : This car is very c...\n",
       "2    I have owed and driven Honda products for 20 y...\n",
       "3    Honda Accord Euro L : The seats are average, b...\n",
       "4     Honda HR-V: Continuous variable transmission ...\n",
       "5    Not much has changed with the historically sec...\n",
       "6    Honda Ballade 150 1.5: This is the most reliab...\n",
       "7    Ride quality is top-notch, though communicatio...\n",
       "8    Honda Jazz Hybrid 1.4 : This is my second Hond...\n",
       "9    The CR-V's voluminous cargo area, quick-foldin...\n",
       "Name: review_text, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Text cleaning tasks"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Word tokenization, lemmatization and stopwords removal"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "using tokens and stopwords removal to remove the noise from the text data.\n",
    "\n",
    "**Next step is lemmatization.**\n",
    "\n",
    "###### *Writing my own words about understanding and its purpose of usage*\n",
    "\n",
    "This is to find the root word of the words/texts in the given dataset, so that we try to minimize the total characters/words as our input to the NLP. The lesser the tokens are, the better the efficiency and performance of the NLP models."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bringing all these requirements into a function\n",
    "\n",
    "*As John recommended...*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:32.290798500Z",
     "start_time": "2026-02-04T06:20:32.274867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# need these for the wordnet_pos_tag usage\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:32.307196300Z",
     "start_time": "2026-02-04T06:20:32.290798500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ,\n",
    "              \"N\": wordnet.NOUN,\n",
    "              \"V\": wordnet.VERB,\n",
    "              \"R\": wordnet.ADV}\n",
    "  return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clean_reviews(review_text):\n",
    "  \"\"\"Clean a single review string.\n",
    "\n",
    "  Improvements added:\n",
    "  - Handles None/NaN inputs safely.\n",
    "  - Normalizes literal \"[NBSP]\" markers and Unicode non-breaking spaces (\\xa0).\n",
    "  - Replaces newlines, carriage returns and tabs with spaces.\n",
    "  - Collapses repeated whitespace to a single space and strips ends.\n",
    "  - Continues lowercasing, punctuation removal, tokenization, lemmatization and stopword removal.\n",
    "  \"\"\"\n",
    "  # handle missing values\n",
    "  if pd.isna(review_text):\n",
    "    return ''\n",
    "\n",
    "  # ensure we have a string\n",
    "  review_text = str(review_text)\n",
    "\n",
    "  # Normalize common NBSP representations (literal marker and unicode non-breaking space)\n",
    "  review_text = review_text.replace('[NBSP]', ' ')\n",
    "  review_text = review_text.replace('\\xa0', ' ')\n",
    "\n",
    "  # Replace newlines, carriage returns and tabs with a space\n",
    "  review_text = re.sub(r'[\\r\\n\\t]+', ' ', review_text)\n",
    "\n",
    "  # Collapse multiple whitespace characters into a single space and strip\n",
    "  review_text = re.sub(r'\\s+', ' ', review_text).strip()\n",
    "\n",
    "  # converting to lower_case\n",
    "  review_text = review_text.lower()\n",
    "\n",
    "  # remove punctuations\n",
    "  review_text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', review_text)\n",
    "\n",
    "  # word tokenization\n",
    "  word_tokens = nltk.word_tokenize(review_text)\n",
    "\n",
    "  # lemmatization\n",
    "  lemmatizer = nltk.WordNetLemmatizer()\n",
    "  lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in word_tokens]\n",
    "\n",
    "  # remove stopwords\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  filtered_tokens = [word for word in lemmatized_tokens if word not in stop_words]\n",
    "  filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "  return filtered_text"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Handling missing values in `review_text`\n",
    "In NLP tasks, rows with missing `review_text` cannot provide any information for sentiment analysis or modeling. Therefore, we should identify and remove these rows before proceeding with cleaning and analysis."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:41.827135700Z",
     "start_time": "2026-02-04T06:20:41.791598900Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df.isnull().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_year        0\n",
       "car_make        0\n",
       "review_text    44\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:45.911515700Z",
     "start_time": "2026-02-04T06:20:45.878020400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for nulls in the review_text column\n",
    "print(f\"Nulls in review_text before: {car_reviews_df['review_text'].isnull().sum()}\")\n",
    "\n",
    "# Drop rows where review_text is null\n",
    "car_reviews_df.dropna(subset=['review_text'], inplace=True)\n",
    "\n",
    "print(f\"Nulls in review_text after: {car_reviews_df['review_text'].isnull().sum()}\")\n",
    "print(f\"DataFrame size after dropping nulls: {len(car_reviews_df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls in review_text before: 44\n",
      "Nulls in review_text after: 0\n",
      "DataFrame size after dropping nulls: 234\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:50.040742900Z",
     "start_time": "2026-02-04T06:20:49.524844200Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df['cleaned_review_text'] = car_reviews_df['review_text'].apply(clean_reviews)",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:52.055319700Z",
     "start_time": "2026-02-04T06:20:52.023303600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove rows that became empty after cleaning (e.g., reviews consisting only of stopwords or punctuation)\n",
    "print(f\"Empty cleaned_review_text before: {(car_reviews_df['cleaned_review_text'] == '').sum()}\")\n",
    "car_reviews_df = car_reviews_df[car_reviews_df['cleaned_review_text'] != '']\n",
    "print(f\"Empty cleaned_review_text after: {(car_reviews_df['cleaned_review_text'] == '').sum()}\")\n",
    "print(f\"Final DataFrame size for modeling: {len(car_reviews_df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty cleaned_review_text before: 0\n",
      "Empty cleaned_review_text after: 0\n",
      "Final DataFrame size for modeling: 234\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:54.816499700Z",
     "start_time": "2026-02-04T06:20:54.793647500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check again the df after cleaning and renaming\n",
    "car_reviews_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 234 entries, 0 to 277\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   car_year             234 non-null    int64 \n",
      " 1   car_make             234 non-null    object\n",
      " 2   review_text          234 non-null    object\n",
      " 3   cleaned_review_text  234 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:20:58.000290700Z",
     "start_time": "2026-02-04T06:20:57.962670800Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df[car_reviews_df['review_text'].isnull()]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [car_year, car_make, review_text, cleaned_review_text]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_year</th>\n",
       "      <th>car_make</th>\n",
       "      <th>review_text</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary from Pre-Processing\n",
    "\n",
    "- We have only 234 reviews in total, after cleaning and removing nulls/empty reviews, for our sentiment analysis task. This is a small dataset for NLP tasks, which may lead to overfitting and limited generalization.\n",
    "- So we are going to use VADER sentiment analysis tool to generate sentiment labels from the reviews, as the dataset does not have any sentiment labels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Option-1: Sentimental analysis using VADER\n",
    "As we have only customer reviews and no sentiment labels in our dataset, we need to generate the sentiment from the customer reviews before we could Label Encode them."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:51:06.370710600Z",
     "start_time": "2026-02-04T05:51:05.218425400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install vaderSentiment if not already installed\n",
    "!pip install vaderSentiment"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from vaderSentiment) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests->vaderSentiment) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests->vaderSentiment) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests->vaderSentiment) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests->vaderSentiment) (2026.1.4)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:21:19.472424700Z",
     "start_time": "2026-02-04T06:21:19.456048100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment intensity analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment scores and labels\n",
    "def get_vader_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return 'Neutral'\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    compound = score['compound']\n",
    "\n",
    "    if compound >= 0.05:\n",
    "        return 'Positive', compound\n",
    "    elif compound <= -0.05:\n",
    "        return 'Negative', compound\n",
    "    else:\n",
    "        return 'Neutral', compound"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:22:58.840895300Z",
     "start_time": "2026-02-04T06:22:58.748731600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the function to the 'review_text' column\n",
    "car_reviews_df[['sentiment_vdr', 'confidence']] = car_reviews_df['cleaned_review_text'].apply(lambda x: pd.Series(get_vader_sentiment(x)))\n",
    "\n",
    "# Display the distribution of generated sentiments\n",
    "print(car_reviews_df['sentiment_vdr'].value_counts())\n",
    "\n",
    "# Display the first few rows with sentiments\n",
    "car_reviews_df[['cleaned_review_text', 'sentiment_vdr', 'confidence']].head(10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_vdr\n",
      "Positive    207\n",
      "Negative     19\n",
      "Neutral       8\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                 cleaned_review_text sentiment_vdr  confidence\n",
       "0  although arguably firstgeneration insights hy...      Positive      0.4767\n",
       "1  2009 honda accord exl 4 car comfortable sporty...      Positive      0.8176\n",
       "2  owe driven honda product 20 year purchase vehi...      Negative     -0.5984\n",
       "3  honda accord euro l seat average little rear l...      Positive      0.7184\n",
       "4  honda hrv continuous variable transmission fai...      Negative     -0.5423\n",
       "5  much change historically secondbestselling hon...      Positive      0.1531\n",
       "6  honda ballade 150 15 reliable car ever comfort...      Positive      0.9242\n",
       "7  ride quality topnotch though communication roa...      Positive      0.8020\n",
       "8  honda jazz hybrid 14 second honda first one ho...      Positive      0.6558\n",
       "9  crvs voluminous cargo area quickfolding seat f...      Positive      0.2960"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>sentiment_vdr</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>although arguably firstgeneration insights hy...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009 honda accord exl 4 car comfortable sporty...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owe driven honda product 20 year purchase vehi...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.5984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honda accord euro l seat average little rear l...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>honda hrv continuous variable transmission fai...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much change historically secondbestselling hon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>honda ballade 150 15 reliable car ever comfort...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ride quality topnotch though communication roa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>honda jazz hybrid 14 second honda first one ho...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crvs voluminous cargo area quickfolding seat f...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Option-2: Using Pre-trained BERT model for sentiment analysis"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:38:45.243446500Z",
     "start_time": "2026-02-04T06:38:35.459309300Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-5.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n",
      "  Downloading huggingface_hub-1.3.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from transformers) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typer-slim (from transformers)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from transformers) (4.67.2)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\aravi\\pycharmmiscproject\\.venv\\lib\\site-packages (from typer-slim->transformers) (8.3.1)\n",
      "Downloading transformers-5.0.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.1/10.1 MB 62.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-1.3.7-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.7/536.7 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 82.6 MB/s eta 0:00:00\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 52.9 MB/s eta 0:00:00\n",
      "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: shellingham, safetensors, pyyaml, hf-xet, h11, fsspec, filelock, anyio, typer-slim, httpcore, httpx, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   -------------- -------------------------  5/14 [fsspec]\n",
      "   -------------------- -------------------  7/14 [anyio]\n",
      "   ------------------------- --------------  9/14 [httpcore]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [huggingface-hub]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ------------------------------------- -- 13/14 [transformers]\n",
      "   ---------------------------------------- 14/14 [transformers]\n",
      "\n",
      "Successfully installed anyio-4.12.1 filelock-3.20.3 fsspec-2026.1.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.3.7 pyyaml-6.0.3 safetensors-0.7.0 shellingham-1.5.4 tokenizers-0.22.2 transformers-5.0.0 typer-slim-0.21.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T06:38:53.080199200Z",
     "start_time": "2026-02-04T06:38:50.348785100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use pre-trained transformer models\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained sentiment model\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "# Analyze your reviews\n",
    "results = sentiment_pipeline(car_reviews_df['cleaned_review_text'].tolist())\n",
    "\n",
    "# Extract predictions\n",
    "car_reviews_df['sentiment_hft'] = [r['label'] for r in results]\n",
    "car_reviews_df['confidence_hft'] = [r['score'] for r in results]\n",
    "\n",
    "print(car_reviews_df[['cleaned_review_text', 'sentiment_hft', 'confidence_hft']].head())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravi\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "C:\\Users\\Aravi\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aravi\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Load pre-trained sentiment model\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m sentiment_pipeline = \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msentiment-analysis\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdistilbert-base-uncased-finetuned-sst-2-english\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m      8\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m# Analyze your reviews\u001B[39;00m\n\u001B[32m     11\u001B[39m results = sentiment_pipeline(car_reviews_df[\u001B[33m'\u001B[39m\u001B[33mcleaned_review_text\u001B[39m\u001B[33m'\u001B[39m].tolist())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:827\u001B[39m, in \u001B[36mpipeline\u001B[39m\u001B[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    823\u001B[39m             \u001B[33m'\u001B[39m\u001B[33mYou cannot use both `pipeline(... dtype=..., model_kwargs=\u001B[39m\u001B[33m{\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m:...})` as those\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    824\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m arguments might conflict, use only one.)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    825\u001B[39m         )\n\u001B[32m    826\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m827\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[43mtorch\u001B[49m, dtype):\n\u001B[32m    828\u001B[39m         dtype = \u001B[38;5;28mgetattr\u001B[39m(torch, dtype)\n\u001B[32m    829\u001B[39m     model_kwargs[\u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m] = dtype\n",
      "\u001B[31mNameError\u001B[39m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label encode the sentiment column"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:52:52.443917100Z",
     "start_time": "2026-02-04T05:52:52.419089700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "car_reviews_df['sentiment_lbl'] = label_encoder.fit_transform(car_reviews_df['sentiment_vdr'])"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:52:58.578987200Z",
     "start_time": "2026-02-04T05:52:58.485364700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(car_reviews_df.head())\n",
    "\n",
    "print(car_reviews_df['sentiment'].value_counts())\n",
    "print(car_reviews_df['sentiment_lbl'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   car_year car_make                                        review_text  \\\n",
      "0      2009    Honda  Although arguably the first-generation Insight...   \n",
      "1      2009    Honda  2009 Honda Accord EX-L 4  : This car is very c...   \n",
      "2      2010    Honda  I have owed and driven Honda products for 20 y...   \n",
      "3      2010    Honda  Honda Accord Euro L : The seats are average, b...   \n",
      "4      2011    Honda   Honda HR-V: Continuous variable transmission ...   \n",
      "\n",
      "                                 cleaned_review_text sentiment  sentiment_lbl  \n",
      "0  although arguably firstgeneration insights hy...  Positive              2  \n",
      "1  2009 honda accord exl 4 car comfortable sporty...  Positive              2  \n",
      "2  owe driven honda product 20 year purchase vehi...  Negative              0  \n",
      "3  honda accord euro l seat average little rear l...  Positive              2  \n",
      "4  honda hrv continuous variable transmission fai...  Negative              0  \n",
      "sentiment\n",
      "Positive    195\n",
      "Neutral      53\n",
      "Negative     30\n",
      "Name: count, dtype: int64\n",
      "sentiment_lbl\n",
      "2    195\n",
      "1     53\n",
      "0     30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Comparing the `CountVectorizer()` vs `TfIdfVectorizer()` from our cleaned review texts"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:53:45.222427500Z",
     "start_time": "2026-02-04T05:53:45.205579700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def compare_vectorizers_logreg(\n",
    "        df,\n",
    "        text_col='cleaned_review_text',\n",
    "        label_col='sentiment_lbl',\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        max_features=5000,\n",
    "        logreg_kwargs=None,\n",
    "        verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Task: Split text/labels, train LogisticRegression with CountVectorizer and TfidfVectorizer,\n",
    "    print dataset sizes + accuracies + winner, and return fitted artifacts for reuse.\n",
    "    \"\"\"\n",
    "    if logreg_kwargs is None:\n",
    "        logreg_kwargs = {}\n",
    "\n",
    "    cleaned_reviews_X = df[text_col]\n",
    "    encoded_sentiments_y = df[label_col]\n",
    "\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "        cleaned_reviews_X, encoded_sentiments_y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Train size: {len(X_train_text)}\")\n",
    "        print(f\"Test size: {len(X_test_text)}\")\n",
    "        print(f\"Total: {len(X_train_text) + len(X_test_text)}\")\n",
    "        print(f\"Original data size: {len(cleaned_reviews_X)}\")\n",
    "\n",
    "    count_vec = CountVectorizer(max_features=max_features)\n",
    "    X_train_count = count_vec.fit_transform(X_train_text)\n",
    "    X_test_count = count_vec.transform(X_test_text)\n",
    "\n",
    "    model_count = LogisticRegression(**logreg_kwargs)\n",
    "    model_count.fit(X_train_count, y_train)\n",
    "    score_count = model_count.score(X_test_count, y_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"CountVectorizer Accuracy: {score_count:.4f}\")\n",
    "\n",
    "    tfidf_vec = TfidfVectorizer(max_features=max_features)\n",
    "    X_train_tfidf = tfidf_vec.fit_transform(X_train_text)\n",
    "    X_test_tfidf = tfidf_vec.transform(X_test_text)\n",
    "\n",
    "    model_tfidf = LogisticRegression(**logreg_kwargs)\n",
    "    model_tfidf.fit(X_train_tfidf, y_train)\n",
    "    score_tfidf = model_tfidf.score(X_test_tfidf, y_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"TfidfVectorizer Accuracy: {score_tfidf:.4f}\")\n",
    "\n",
    "        if score_tfidf > score_count:\n",
    "            print(f\"\\n✅ TfidfVectorizer wins by {(score_tfidf - score_count) * 100:.2f}%\")\n",
    "        elif score_tfidf == score_count:\n",
    "            print(f\"\\n✅ Tie: Both models perform equally well\")\n",
    "        else:\n",
    "            print(f\"\\n✅ CountVectorizer wins by {(score_count - score_tfidf) * 100:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        'X_train_text': X_train_text,\n",
    "        'X_test_text': X_test_text,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'count_vectorizer': count_vec,\n",
    "        'tfidf_vectorizer': tfidf_vec,\n",
    "        'count_model': model_count,\n",
    "        'tfidf_model': model_tfidf,\n",
    "        'count_accuracy': score_count,\n",
    "        'tfidf_accuracy': score_tfidf,\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:53:58.745699900Z",
     "start_time": "2026-02-04T05:53:58.683687200Z"
    }
   },
   "cell_type": "code",
   "source": "results = compare_vectorizers_logreg(car_reviews_df)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 222\n",
      "Test size: 56\n",
      "Total: 278\n",
      "Original data size: 278\n",
      "CountVectorizer Accuracy: 0.8214\n",
      "TfidfVectorizer Accuracy: 0.7679\n",
      "\n",
      "✅ CountVectorizer wins by 5.36%\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:54:14.129013600Z",
     "start_time": "2026-02-04T05:54:14.093589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make sure these are different\n",
    "print(\"\\nFirst 3 train reviews:\")\n",
    "print(results['X_train_text'][:3])\n",
    "print(\"\\nFirst 3 test reviews:\")\n",
    "print(results['X_test_text'][:3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 train reviews:\n",
      "260                                                     \n",
      "124    2019 buick regal offer plenty cargo space good...\n",
      "33     2015 hyundai sonata limited 24 seat beautiful ...\n",
      "Name: cleaned_review_text, dtype: object\n",
      "\n",
      "First 3 test reviews:\n",
      "30     hyundai build warm hatch elantra sedan good co...\n",
      "126    purchase vehicle replacement yukon denali tota...\n",
      "199    acura mdx sport hybrid lot go crossover lack a...\n",
      "Name: cleaned_review_text, dtype: object\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# checking for data integrity between training and test data\n",
    "print(f\"Total reviews: {len(car_reviews_df['cleaned_review_text'])}\")\n",
    "print(f\"Train set: {len(results['y_train'])}\")\n",
    "print(f\"Test set: {len(results['y_test'])}\")\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nLabel distribution in test set:\")\n",
    "print(pd.Series(results['y_test']).value_counts())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Below code was derived with the help of ClaudeCode AI assistant to perform some diagnostics to check for data leakage and other potential issues with the model performance.*"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1. Check for data leakage\n",
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC 1: Data Leakage Check\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train size: {len(results['X_train_text'])}\")\n",
    "print(f\"Test size: {len(results['X_test_text'])}\")\n",
    "print(f\"Overlap: {len(set(results['X_train_text']) & set(results['X_test_text']))} reviews\")\n",
    "if len(set(results['X_train_text']) & set(results['X_test_text'])) > 0:\n",
    "    print(\"⚠️ WARNING: Train and test sets overlap!\")\n",
    "\n",
    "# 2. Cross-validation (more realistic)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC 2: Cross-Validation Scores\")\n",
    "print(\"=\"*60)\n",
    "# We need to vectorize before cross_val_score if we want to use the text directly,\n",
    "# or use the already vectorized data.\n",
    "X_tfidf = results['tfidf_vectorizer'].transform(results['X_train_text'])\n",
    "cv_scores = cross_val_score(results['tfidf_model'], X_tfidf, results['y_train'], cv=5)\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "if cv_scores.mean() < 0.95:\n",
    "    print(\"✅ More realistic scores - model isn't just memorizing\")\n",
    "else:\n",
    "    print(\"⚠️ Still suspiciously high\")\n",
    "\n",
    "# 3. Dataset size and distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC 3: Dataset Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(car_reviews_df['cleaned_review_text'])}\")\n",
    "print(f\"Classes: {len(set(results['y_train']))}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(pd.Series(results['y_train']).value_counts())\n",
    "print(f\"\\nAverage review length: {np.mean([len(str(r).split()) for r in results['X_train_text']]):.1f} words\")\n",
    "\n",
    "# 4. Look at what model is using\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC 4: Most Important Features\")\n",
    "print(\"=\"*60)\n",
    "feature_names = results['tfidf_vectorizer'].get_feature_names_out()\n",
    "if hasattr(results['tfidf_model'], 'coef_'):\n",
    "    # For binary/multiclass logistic regression\n",
    "    for idx, class_name in enumerate(label_encoder.classes_):\n",
    "        top_features = np.argsort(results['tfidf_model'].coef_[idx])[-10:]\n",
    "        print(f\"\\nTop features for '{class_name}':\")\n",
    "        print([feature_names[i] for i in top_features])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Findings summary\n",
    "\n",
    "So far, the two vectorization techniques have been compared using Logistic Regression as the model. The TfidfVectorizer has shown a slight edge in accuracy over CountVectorizer. But still they show 100% accuracy which is suspiciously high for a real-world NLP task, indicating potential data leakage. The above some extra analysis diagnostics were performed to check for data leakage, cross-validation scores, dataset size and distribution, and important features used by the model. To address this, I am going to try check the uniquess of the reviews and resolve them."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TRIAL 1 -Remove duplicates BEFORE splitting\n",
    "unique_reviews_df_1 = car_reviews_df.drop_duplicates(subset=['cleaned_review_text'], keep='first')\n",
    "print(f\"Original size: {len(car_reviews_df)}\")\n",
    "print(f\"After removing duplicates: {len(unique_reviews_df_1)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TRIAL 2 - Try with the dupes removal on the original reviews_text column\n",
    "unique_reviews_df = car_reviews_df.drop_duplicates(subset=['review_text'], keep='first')\n",
    "print(f\"Original size: {len(car_reviews_df)}\")\n",
    "print(f\"After removing duplicates based on original review_text: {len(unique_reviews_df)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After carefully reviewing the data, we have to take only 300 unique reviews for our further analysis to avoid data leakage. So, we will proceed with the `unique_reviews_df` DataFrame for the next steps."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique_reviews_df['cleaned_reviews_v2'] = unique_reviews_df['review_text'].apply(clean_reviews)\n",
    "\n",
    "unique_reviews_df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "unique_review_comparison_results = compare_vectorizers_logreg(df=unique_reviews_df, text_col='cleaned_review_text', label_col='sentiment_lbl')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task-2 sentimental analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Task\n",
    "Perform sentiment analysis on the `Car_Reviews_Database.csv` dataset. This involves splitting the preprocessed and vectorized text data into training and testing sets, then training and evaluating both Logistic Regression and Naïve Bayes models. Additionally, prepare the cleaned text data for deep learning by tokenizing, creating word embeddings, and padding sequences, followed by building and evaluating an LSTM neural network. Finally, install the Hugging Face Transformers library, tokenize the cleaned text data for BERT, and then build and evaluate a pre-trained BERT model fine-tuned for sentiment classification."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using TF-IDF vectorized data from unique_review_comparison_results\n",
    "X = unique_review_comparison_results['tfidf_vectorizer'].transform(unique_reviews_df['cleaned_review_text']).toarray()\n",
    "y = unique_reviews_df['sentiment'].astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build and Evaluate Logistic Regression Model\n",
    "\n",
    "### Subtask:\n",
    "Train a Logistic Regression model on the training data and evaluate its performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "To train and evaluate a Logistic Regression model, I will import the necessary classes and functions, initialize the model, fit it to the training data, make predictions on the test data, and then calculate and print the required evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "# max_iter is set to a higher value to ensure convergence\n",
    "# solver='liblinear' is generally good for small datasets or when L1/L2 regularization is used\n",
    "log_reg_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "print(\"Training Logistic Regression model...\")\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "precision_log_reg = precision_score(y_test, y_pred_log_reg, average='weighted')\n",
    "recall_log_reg = recall_score(y_test, y_pred_log_reg, average='weighted')\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg, average='weighted')\n",
    "\n",
    "print(f\"\\n--- Logistic Regression Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_log_reg:.4f}\")\n",
    "print(f\"Precision (weighted): {precision_log_reg:.4f}\")\n",
    "print(f\"Recall (weighted): {recall_log_reg:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1_log_reg:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build and Evaluate Naïve Bayes Model\n",
    "\n",
    "### Subtask:\n",
    "Train a Naïve Bayes classifier on the training data and evaluate its performance using appropriate metrics.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Reasoning:\n",
    "To train and evaluate a Naïve Bayes model, I will import the necessary classes and functions, initialize the model, fit it to the training data, make predictions on the test data, and then calculate and print the required evaluation metrics."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "Implement the Naïve Bayes model training and evaluation as described in the instructions, including importing necessary libraries, initializing the model, fitting it to the training data, making predictions, and calculating evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB(fit_prior=True, class_prior=None)\n",
    "\n",
    "# Fit the model to the training data\n",
    "print(\"Training Naïve Bayes model...\")\n",
    "nb_model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb, average='weighted')\n",
    "recall_nb = recall_score(y_test, y_pred_nb, average='weighted')\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "\n",
    "print(f\"\\n--- Naïve Bayes Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
    "print(f\"Precision (weighted): {precision_nb:.4f}\")\n",
    "print(f\"Recall (weighted): {recall_nb:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1_nb:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare Data for Deep Learning Models (LSTM)\n",
    "\n",
    "### Subtask:\n",
    "Tokenize the cleaned text data for deep learning, create word embeddings, and pad sequences to a uniform length for LSTM input.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "To prepare the cleaned text data for deep learning models like LSTM, I will first import the necessary Keras utilities. Then, I'll initialize a Tokenizer to build a vocabulary from the cleaned reviews, convert these texts into numerical sequences, and finally pad these sequences to a uniform length suitable for neural network input.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize a Tokenizer\n",
    "# Set num_words to a suitable number based on your vocabulary size. Let's use 5000 as a starting point.\n",
    "# The vocab from CountVectorizer had 111 unique words, so 5000 is more than enough.\n",
    "# We will use the 'cleaned_review_text' column for this.\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<unk>')\n",
    "\n",
    "# Fit the tokenizer on the 'cleaned_review_text' column to build the vocabulary\n",
    "print(\"Fitting tokenizer on cleaned review text...\")\n",
    "tokenizer.fit_on_texts(car_reviews_df['cleaned_review_text'])\n",
    "print(\"Tokenizer fitting complete.\")\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "print(\"Converting texts to sequences...\")\n",
    "sequences = tokenizer.texts_to_sequences(car_reviews_df['cleaned_review_text'])\n",
    "print(\"Text to sequence conversion complete.\")\n",
    "\n",
    "# Determine the maximum sequence length\n",
    "max_sequence_length = max([len(x) for x in sequences])\n",
    "print(f\"Maximum sequence length: {max_sequence_length}\")\n",
    "\n",
    "# Pad the sequences to a uniform length\n",
    "# Use 'post' padding and truncation to maintain the beginning of the reviews\n",
    "print(\"Padding sequences...\")\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "print(\"Sequence padding complete.\")\n",
    "\n",
    "print(f\"Shape of padded sequences: {padded_sequences.shape}\")\n",
    "# Display the first 5 padded sequences\n",
    "print(\"\\nFirst 5 padded sequences:\")\n",
    "print(padded_sequences[:5])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "Now that the text data has been tokenized and padded, the next step in preparing data for deep learning models like LSTM is to prepare the target variable for model training. This involves encoding the categorical sentiment labels into a numerical format suitable for deep learning, such as one-hot encoding or label encoding, depending on the model's output layer.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encode the target variable (sentiment) to numerical values\n",
    "print(\"Encoding sentiment labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(car_reviews_df['sentiment'])\n",
    "\n",
    "# Convert integer labels to one-hot encoded vectors for multi-class classification\n",
    "y_dl = to_categorical(y_encoded)\n",
    "print(\"Sentiment labels encoded and one-hot converted.\")\n",
    "\n",
    "print(f\"Shape of one-hot encoded labels (y_dl): {y_dl.shape}\")\n",
    "print(\"First 5 one-hot encoded labels:\")\n",
    "print(y_dl[:5])\n",
    "print(\"Original sentiment categories:\", label_encoder.classes_)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "The data has been preprocessed for deep learning models. Now, I need to split the padded sequences (features) and the one-hot encoded labels (target) into training and testing sets to prepare for building the LSTM model.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the padded sequences and one-hot encoded labels into training and testing sets\n",
    "# Use a test_size of 0.2 and random_state for reproducibility\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(padded_sequences, y_dl, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of X_train_dl: {X_train_dl.shape}\")\n",
    "print(f\"Shape of X_test_dl: {X_test_dl.shape}\")\n",
    "print(f\"Shape of y_train_dl: {y_train_dl.shape}\")\n",
    "print(f\"Shape of y_test_dl: {y_test_dl.shape}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build and Evaluate LSTM Model\n",
    "\n",
    "### Subtask:\n",
    "Construct and train an LSTM (Long Short-Term Memory) neural network for sentiment classification, then evaluate its performance.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "To construct and train the LSTM model, I will import the necessary Keras layers, define model parameters, build a Sequential model with Embedding, SpatialDropout1D, LSTM, and Dense layers, compile it, and then train and evaluate it using the prepared deep learning datasets.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "\n",
    "# 1. Define model parameters\n",
    "vocabulary_size = tokenizer.num_words\n",
    "embedding_dim = 128 # A common choice for embedding dimensions\n",
    "input_length = max_sequence_length\n",
    "num_sentiment_classes = y_dl.shape[1]\n",
    "\n",
    "print(f\"Vocabulary size: {vocabulary_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Input sequence length: {input_length}\")\n",
    "print(f\"Number of sentiment classes: {num_sentiment_classes}\")\n",
    "\n",
    "# 2. Build the LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=input_length),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(128),\n",
    "    Dense(num_sentiment_classes, activation='softmax')\n",
    "])\n",
    "print(\"LSTM model built.\")\n",
    "\n",
    "# 3. Compile the model\n",
    "print(\"Compiling LSTM model...\")\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"LSTM model compiled.\")\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "# 4. Train the LSTM model\n",
    "print(\"Training LSTM model...\")\n",
    "history = lstm_model.fit(\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    epochs=5, # Number of epochs can be tuned\n",
    "    batch_size=128, # Batch size can be tuned\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    verbose=1\n",
    ")\n",
    "print(\"LSTM model training complete.\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"Evaluating LSTM model performance on test set...\")\n",
    "loss, accuracy = lstm_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "\n",
    "print(f\"\\n--- LSTM Model Evaluation ---\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "The previous code produced a warning about the deprecated `input_length` argument in the `Embedding` layer. Removing this argument will resolve the warning as Keras can infer the input length from the input data.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "\n",
    "# 1. Define model parameters\n",
    "vocabulary_size = tokenizer.num_words\n",
    "embedding_dim = 128 # A common choice for embedding dimensions\n",
    "input_length = max_sequence_length\n",
    "num_sentiment_classes = y_dl.shape[1]\n",
    "\n",
    "print(f\"Vocabulary size: {vocabulary_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Input sequence length: {input_length}\")\n",
    "print(f\"Number of sentiment classes: {num_sentiment_classes}\")\n",
    "\n",
    "# 2. Build the LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=vocabulary_size, output_dim=embedding_dim), # Removed input_length\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(128),\n",
    "    Dense(num_sentiment_classes, activation='softmax')\n",
    "])\n",
    "print(\"LSTM model built.\")\n",
    "\n",
    "# 3. Compile the model\n",
    "print(\"Compiling LSTM model...\")\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"LSTM model compiled.\")\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "# 4. Train the LSTM model\n",
    "print(\"Training LSTM model...\")\n",
    "history = lstm_model.fit(\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    epochs=5, # Number of epochs can be tuned\n",
    "    batch_size=128, # Batch size can be tuned\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    verbose=1\n",
    ")\n",
    "print(\"LSTM model training complete.\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"Evaluating LSTM model performance on test set...\")\n",
    "loss, accuracy = lstm_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "\n",
    "print(f\"\\n--- LSTM Model Evaluation ---\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare Data for BERT Model\n",
    "\n",
    "### Subtask:\n",
    "Install the Hugging Face Transformers library and tokenize the cleaned text data for BERT."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "The next step is to install the Hugging Face Transformers library, which is necessary for working with BERT models.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install transformers"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "With the `transformers` library installed, I will now import the necessary BERT tokenizer and tokenize the `cleaned_review_text` column from the DataFrame. This prepares the text data into an input format suitable for BERT models.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Function to tokenize and encode text for BERT\n",
    "def tokenize_for_bert(text, tokenizer, max_len=128):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,      # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Return attention mask.\n",
    "                        return_tensors = 'pt',     # Return PyTorch tensors.\n",
    "                   )\n",
    "    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
    "\n",
    "print(\"Tokenizing and encoding text for BERT...\")\n",
    "# Apply the tokenizer to the 'cleaned_review_text' column\n",
    "bert_input_ids = []\n",
    "bert_attention_masks = []\n",
    "\n",
    "max_bert_len = 128 # Define a max length for BERT sequences\n",
    "\n",
    "for text in car_reviews_df['cleaned_review_text']:\n",
    "    input_id, attention_mask = tokenize_for_bert(text, tokenizer_bert, max_bert_len)\n",
    "    bert_input_ids.append(input_id)\n",
    "    bert_attention_masks.append(attention_mask)\n",
    "\n",
    "# Convert the lists of tensors into single tensors\n",
    "bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
    "bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
    "\n",
    "print(\"Tokenization and encoding complete.\")\n",
    "print(f\"Shape of BERT input IDs: {bert_input_ids.shape}\")\n",
    "print(f\"Shape of BERT attention masks: {bert_attention_masks.shape}\")\n",
    "\n",
    "# Prepare the labels for BERT (using the previously encoded y_encoded)\n",
    "# Convert y_encoded to a PyTorch tensor\n",
    "labels_bert = torch.tensor(y_encoded)\n",
    "print(f\"Shape of BERT labels: {labels_bert.shape}\")"
   ]
  }
 ]
}
