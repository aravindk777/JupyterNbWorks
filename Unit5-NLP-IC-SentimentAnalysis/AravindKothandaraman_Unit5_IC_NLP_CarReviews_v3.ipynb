{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "-sXQv02x7Rs3",
    "UMIuLJIi7Wf1",
    "Waty-esn7fi3",
    "dDxQeXS-9q74"
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5cae758cf43a4e8fa7e02a8a2f25dfad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9a130a1a243d4291a1a8c920e8737242",
       "IPY_MODEL_0e41926a2993474a83067d7a87e8bc0a",
       "IPY_MODEL_96c6bf4a11a142d5896a11f9669280ba"
      ],
      "layout": "IPY_MODEL_84d9b665f16849138e40643c936adb3a"
     }
    },
    "9a130a1a243d4291a1a8c920e8737242": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf6a8708619d42d2b650cf68ddc41aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_e156cbf154ac4647adcc202b70655259",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "0e41926a2993474a83067d7a87e8bc0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_deed6951a3ae448fb3ff6c3edfcbb9be",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f62a1f757aa3461bbc26531630769745",
      "value": 48
     }
    },
    "96c6bf4a11a142d5896a11f9669280ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a77173078e114ff48b393ba1d5f37b88",
      "placeholder": "​",
      "style": "IPY_MODEL_7b5c947189364d388c33705537124f7e",
      "value": " 48.0/48.0 [00:00&lt;00:00, 1.34kB/s]"
     }
    },
    "84d9b665f16849138e40643c936adb3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf6a8708619d42d2b650cf68ddc41aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e156cbf154ac4647adcc202b70655259": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "deed6951a3ae448fb3ff6c3edfcbb9be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f62a1f757aa3461bbc26531630769745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a77173078e114ff48b393ba1d5f37b88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b5c947189364d388c33705537124f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee540ac34a1a47b7a56b4c14a2342982": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9cd26aebe0f4b74b1e93dfe8a741a0d",
       "IPY_MODEL_15a7597713ce466c962a34809cf2b646",
       "IPY_MODEL_569e4c4df6d246e8a1584e9de1fdaf52"
      ],
      "layout": "IPY_MODEL_8bbd1cd1097747b7ba1da78b5ad3c87d"
     }
    },
    "c9cd26aebe0f4b74b1e93dfe8a741a0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e604c25daef4ed59fee0c17cb8f2114",
      "placeholder": "​",
      "style": "IPY_MODEL_e0669a3f53c148cd9c76860484ef2eb3",
      "value": "vocab.txt: 100%"
     }
    },
    "15a7597713ce466c962a34809cf2b646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e82e75cdedc49d9ba26ed371afbd150",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_329079f983df483aaec7e856f69b3584",
      "value": 231508
     }
    },
    "569e4c4df6d246e8a1584e9de1fdaf52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79cd8bcf772a41ca9f0532033c9d58de",
      "placeholder": "​",
      "style": "IPY_MODEL_1db267536a0d41e5a9a4d67d98690eac",
      "value": " 232k/232k [00:00&lt;00:00, 1.03MB/s]"
     }
    },
    "8bbd1cd1097747b7ba1da78b5ad3c87d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e604c25daef4ed59fee0c17cb8f2114": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0669a3f53c148cd9c76860484ef2eb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e82e75cdedc49d9ba26ed371afbd150": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "329079f983df483aaec7e856f69b3584": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79cd8bcf772a41ca9f0532033c9d58de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1db267536a0d41e5a9a4d67d98690eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc0f862d7e7942b7912329f58d701a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a452cebd66247bb9b5680e4c7a39248",
       "IPY_MODEL_80343f0b8905457abfa00b1733f2a7b5",
       "IPY_MODEL_7faca56a24e245c7ba34f54e89ba2e90"
      ],
      "layout": "IPY_MODEL_4120070166604abd83ba1736139b2d5d"
     }
    },
    "2a452cebd66247bb9b5680e4c7a39248": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_190a3b8ea9cf43b697b4d64d1b18de90",
      "placeholder": "​",
      "style": "IPY_MODEL_c7aea070847d4f25949d8ab718ebde8c",
      "value": "tokenizer.json: 100%"
     }
    },
    "80343f0b8905457abfa00b1733f2a7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43d471525f944c23901b051c8568cb57",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a74899fb027b4a72adb7845f7c93dd7f",
      "value": 466062
     }
    },
    "7faca56a24e245c7ba34f54e89ba2e90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18bc6125404b44d88dabe400046695c5",
      "placeholder": "​",
      "style": "IPY_MODEL_75f5ae56eb334772965a5930e86bfec3",
      "value": " 466k/466k [00:00&lt;00:00, 1.01MB/s]"
     }
    },
    "4120070166604abd83ba1736139b2d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "190a3b8ea9cf43b697b4d64d1b18de90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7aea070847d4f25949d8ab718ebde8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43d471525f944c23901b051c8568cb57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a74899fb027b4a72adb7845f7c93dd7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "18bc6125404b44d88dabe400046695c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75f5ae56eb334772965a5930e86bfec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "186f6362e5a9404980ffb41af7590e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc3b8632ebbe4e0d90482fd9d8cbf3bd",
       "IPY_MODEL_c6993608a5e64fa380f1a856baa30c48",
       "IPY_MODEL_54881e1b21c24951b8e83d85687a825d"
      ],
      "layout": "IPY_MODEL_1163a340d9384a6ea02b4d7edf2fa121"
     }
    },
    "bc3b8632ebbe4e0d90482fd9d8cbf3bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cb5e33a5f344a86905b07f421cb02b5",
      "placeholder": "​",
      "style": "IPY_MODEL_038d2a42ef7a4ac1b8f834c6875d3c41",
      "value": "config.json: 100%"
     }
    },
    "c6993608a5e64fa380f1a856baa30c48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43cda19902664853a9efb826cbc6de78",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68d72d7df916461281c59ff927f495bf",
      "value": 570
     }
    },
    "54881e1b21c24951b8e83d85687a825d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4331e9241b04383b6864fb681b63f8b",
      "placeholder": "​",
      "style": "IPY_MODEL_d8d804be4bcd40a4aa7c071e9b95bc6e",
      "value": " 570/570 [00:00&lt;00:00, 72.2kB/s]"
     }
    },
    "1163a340d9384a6ea02b4d7edf2fa121": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cb5e33a5f344a86905b07f421cb02b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "038d2a42ef7a4ac1b8f834c6875d3c41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43cda19902664853a9efb826cbc6de78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68d72d7df916461281c59ff927f495bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4331e9241b04383b6864fb681b63f8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8d804be4bcd40a4aa7c071e9b95bc6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Unit 5 - Incremental Capstone - NLP\n",
    "\n",
    "### Aravind Kothandaraman\n",
    "2509 batch\n",
    "\n",
    "#### This is being worked upon using the \"car reviews\" zip file dataset provided in the IC dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Install and Import necessary packages"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Install required packages (only once; skip if already installed)\n",
    "# NLTK (Natural Language Toolkit) is a Python library for teaching and working with human language data, offering tools for tokenization, tagging, and parsing.\n",
    "!pip install nltk"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:53.875030400Z",
     "start_time": "2026-02-03T01:40:53.825425100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the necessary packages\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:55.725963Z",
     "start_time": "2026-02-03T01:40:55.496287800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')  # Sentence tokenizer\n",
    "nltk.download('words')  # English word list\n",
    "nltk.download('stopwords')  # Common stopwords\n",
    "nltk.download('wordnet')  # WordNet lexical database\n",
    "nltk.download('punkt_tab') # Download punkt_tab resource"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:58.421438900Z",
     "start_time": "2026-02-03T01:40:58.362183300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import WordNet, a lexical database used for lemmatization and semantic analysis\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Import a list of common English stopwords (e.g., \"the\", \"and\", \"is\") used for filtering out non-informative words\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:22.580472100Z",
     "start_time": "2026-02-03T01:39:22.531355200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Load the \"reviews.zip\" dataset, extract the dataset file and cleanse/preprocess the text data.\n",
    "\n",
    "## *Task-1 work from IC*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract the dataset from the zip file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:25.534898400Z",
     "start_time": "2026-02-03T01:39:25.484186100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_zip = 'review.zip'\n",
    "import zipfile\n",
    "with zipfile.ZipFile(source_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the data and review"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:29.537989800Z",
     "start_time": "2026-02-03T01:39:29.492221600Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = 'Car_Reviews_Database.csv'",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:32.351070100Z",
     "start_time": "2026-02-03T01:39:32.303847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tried with the `utf-8` encoding, but it didnt work.\n",
    "# attempted with `latin1` encoding and it worked.\n",
    "car_reviews_df = pd.read_csv(dataset, encoding=\"latin1\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:34.063107200Z",
     "start_time": "2026-02-03T01:39:33.985929Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df.describe()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              Year\n",
       "count   278.000000\n",
       "mean   2014.143885\n",
       "std       3.095498\n",
       "min    2009.000000\n",
       "25%    2011.250000\n",
       "50%    2014.000000\n",
       "75%    2017.000000\n",
       "max    2019.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2014.143885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.095498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:37.726408200Z",
     "start_time": "2026-02-03T01:39:37.616758100Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Year    278 non-null    int64 \n",
      " 1   Model   278 non-null    object\n",
      " 2   Review  234 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:39:39.234993900Z",
     "start_time": "2026-02-03T01:39:39.137710Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df.head(10)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Year Model                                              Review\n",
       "0  2009  Honda  Although arguably the first-generation Insight...\n",
       "1  2009  Honda  2009 Honda Accord EX-L 4  : This car is very c...\n",
       "2  2010  Honda  I have owed and driven Honda products for 20 y...\n",
       "3  2010  Honda  Honda Accord Euro L : The seats are average, b...\n",
       "4  2011  Honda   Honda HR-V: Continuous variable transmission ...\n",
       "5  2011  Honda  Not much has changed with the historically sec...\n",
       "6  2012  Honda  Honda Ballade 150 1.5: This is the most reliab...\n",
       "7  2012  Honda  Ride quality is top-notch, though communicatio...\n",
       "8  2013  Honda  Honda Jazz Hybrid 1.4 : This is my second Hond...\n",
       "9  2013  Honda  The CR-V's voluminous cargo area, quick-foldin..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Although arguably the first-generation Insight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2009 Honda Accord EX-L 4  : This car is very c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Honda</td>\n",
       "      <td>I have owed and driven Honda products for 20 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda Accord Euro L : The seats are average, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda HR-V: Continuous variable transmission ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Not much has changed with the historically sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda Ballade 150 1.5: This is the most reliab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Ride quality is top-notch, though communicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Honda Jazz Hybrid 1.4 : This is my second Hond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>Honda</td>\n",
       "      <td>The CR-V's voluminous cargo area, quick-foldin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing - Rename columns for easier handling"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:03.123122300Z",
     "start_time": "2026-02-03T01:40:03.064964600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rename columns for easier handling\n",
    "car_reviews_df.rename(columns={'Review': 'review_text', 'Model ': 'car_make', 'Year': 'car_year'}, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:05.485888300Z",
     "start_time": "2026-02-03T01:40:05.390422900Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df['review_text'].head(10)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Although arguably the first-generation Insight...\n",
       "1    2009 Honda Accord EX-L 4  : This car is very c...\n",
       "2    I have owed and driven Honda products for 20 y...\n",
       "3    Honda Accord Euro L : The seats are average, b...\n",
       "4     Honda HR-V: Continuous variable transmission ...\n",
       "5    Not much has changed with the historically sec...\n",
       "6    Honda Ballade 150 1.5: This is the most reliab...\n",
       "7    Ride quality is top-notch, though communicatio...\n",
       "8    Honda Jazz Hybrid 1.4 : This is my second Hond...\n",
       "9    The CR-V's voluminous cargo area, quick-foldin...\n",
       "Name: review_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text cleaning tasks"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Word tokenization, lemmatization and stopwords removal"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "using tokens and stopwords removal to remove the noise from the text data.\n",
    "\n",
    "**Next step is lemmatization.**\n",
    "\n",
    "###### *Writing my own words about understanding and its purpose of usage*\n",
    "\n",
    "This is to find the root word of the words/texts in the given dataset, so that we try to minimize the total characters/words as our input to the NLP. The lesser the tokens are, the better the efficiency and performance of the NLP models."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bringing all these requirements into a function\n",
    "\n",
    "*As John recommended...*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:09.718168700Z",
     "start_time": "2026-02-03T01:40:09.498795100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# need these for the wordnet_pos_tag usage\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:40:12.542109800Z",
     "start_time": "2026-02-03T01:40:12.502764400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ,\n",
    "              \"N\": wordnet.NOUN,\n",
    "              \"V\": wordnet.VERB,\n",
    "              \"R\": wordnet.ADV}\n",
    "  return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clean_reviews(review_text):\n",
    "  \"\"\"Clean a single review string.\n",
    "\n",
    "  Improvements added:\n",
    "  - Handles None/NaN inputs safely.\n",
    "  - Normalizes literal \"[NBSP]\" markers and Unicode non-breaking spaces (\\xa0).\n",
    "  - Replaces newlines, carriage returns and tabs with spaces.\n",
    "  - Collapses repeated whitespace to a single space and strips ends.\n",
    "  - Continues lowercasing, punctuation removal, tokenization, lemmatization and stopword removal.\n",
    "  \"\"\"\n",
    "  # handle missing values\n",
    "  if pd.isna(review_text):\n",
    "    return ''\n",
    "\n",
    "  # ensure we have a string\n",
    "  review_text = str(review_text)\n",
    "\n",
    "  # Normalize common NBSP representations (literal marker and unicode non-breaking space)\n",
    "  review_text = review_text.replace('[NBSP]', ' ')\n",
    "  review_text = review_text.replace('\\xa0', ' ')\n",
    "\n",
    "  # Replace newlines, carriage returns and tabs with a space\n",
    "  review_text = re.sub(r'[\\r\\n\\t]+', ' ', review_text)\n",
    "\n",
    "  # Collapse multiple whitespace characters into a single space and strip\n",
    "  review_text = re.sub(r'\\s+', ' ', review_text).strip()\n",
    "\n",
    "  # converting to lower_case\n",
    "  review_text = review_text.lower()\n",
    "\n",
    "  # remove punctuations\n",
    "  review_text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', review_text)\n",
    "\n",
    "  # word tokenization\n",
    "  word_tokens = nltk.word_tokenize(review_text)\n",
    "\n",
    "  # lemmatization\n",
    "  lemmatizer = nltk.WordNetLemmatizer()\n",
    "  lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in word_tokens]\n",
    "\n",
    "  # remove stopwords\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  filtered_tokens = [word for word in lemmatized_tokens if word not in stop_words]\n",
    "  filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "  return filtered_text"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T01:41:12.942242800Z",
     "start_time": "2026-02-03T01:41:07.397507300Z"
    }
   },
   "cell_type": "code",
   "source": "car_reviews_df['cleaned_review_text'] = car_reviews_df['review_text'].apply(clean_reviews)",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label encode the sentiment column"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "car_reviews_df['sentiment_lbl'] = label_encoder.fit_transform(car_reviews_df['sentiment'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(car_reviews_df.head())\n",
    "\n",
    "print(car_reviews_df['sentiment'].value_counts())\n",
    "print(car_reviews_df['sentiment_lbl'].value_counts())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Comparing the `CountVectorizer()` vs `TfIdfVectorizer()` from our cleaned review texts"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def compare_vectorizers_logreg(\n",
    "        df,\n",
    "        text_col='cleaned_review_text',\n",
    "        label_col='sentiment_lbl',\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        max_features=5000,\n",
    "        logreg_kwargs=None,\n",
    "        verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Task: Split text/labels, train LogisticRegression with CountVectorizer and TfidfVectorizer,\n",
    "    print dataset sizes + accuracies + winner, and return fitted artifacts for reuse.\n",
    "    \"\"\"\n",
    "    if logreg_kwargs is None:\n",
    "        logreg_kwargs = {}\n",
    "\n",
    "    cleaned_reviews_X = df[text_col]\n",
    "    encoded_sentiments_y = df[label_col]\n",
    "\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "        cleaned_reviews_X, encoded_sentiments_y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Train size: {len(X_train_text)}\")\n",
    "        print(f\"Test size: {len(X_test_text)}\")\n",
    "        print(f\"Total: {len(X_train_text) + len(X_test_text)}\")\n",
    "        print(f\"Original data size: {len(cleaned_reviews_X)}\")\n",
    "\n",
    "    count_vec = CountVectorizer(max_features=max_features)\n",
    "    X_train_count = count_vec.fit_transform(X_train_text)\n",
    "    X_test_count = count_vec.transform(X_test_text)\n",
    "\n",
    "    model_count = LogisticRegression(**logreg_kwargs)\n",
    "    model_count.fit(X_train_count, y_train)\n",
    "    score_count = model_count.score(X_test_count, y_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"CountVectorizer Accuracy: {score_count:.4f}\")\n",
    "\n",
    "    tfidf_vec = TfidfVectorizer(max_features=max_features)\n",
    "    X_train_tfidf = tfidf_vec.fit_transform(X_train_text)\n",
    "    X_test_tfidf = tfidf_vec.transform(X_test_text)\n",
    "\n",
    "    model_tfidf = LogisticRegression(**logreg_kwargs)\n",
    "    model_tfidf.fit(X_train_tfidf, y_train)\n",
    "    score_tfidf = model_tfidf.score(X_test_tfidf, y_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"TfidfVectorizer Accuracy: {score_tfidf:.4f}\")\n",
    "\n",
    "        if score_tfidf > score_count:\n",
    "            print(f\"\\n✅ TfidfVectorizer wins by {(score_tfidf - score_count) * 100:.2f}%\")\n",
    "        elif score_tfidf == score_count:\n",
    "            print(f\"\\n✅ Tie: Both models perform equally well\")\n",
    "        else:\n",
    "            print(f\"\\n✅ CountVectorizer wins by {(score_count - score_tfidf) * 100:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        'X_train_text': X_train_text,\n",
    "        'X_test_text': X_test_text,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'count_vectorizer': count_vec,\n",
    "        'tfidf_vectorizer': tfidf_vec,\n",
    "        'count_model': model_count,\n",
    "        'tfidf_model': model_tfidf,\n",
    "        'count_accuracy': score_count,\n",
    "        'tfidf_accuracy': score_tfidf,\n",
    "    }\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results = compare_vectorizers_logreg(bikerental_reviews_df)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make sure these are different\n",
    "print(\"\\nFirst 3 train reviews:\")\n",
    "print(results['X_train_text'][:3])\n",
    "print(\"\\nFirst 3 test reviews:\")\n",
    "print(results['X_test_text'][:3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# checking for data integrity between training and test data\n",
    "print(f\"Total reviews: {len(bikerental_reviews_df['cleaned_review_text'])}\")\n",
    "print(f\"Train set: {len(results['y_train'])}\")\n",
    "print(f\"Test set: {len(results['y_test'])}\")\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nLabel distribution in test set:\")\n",
    "print(pd.Series(results['y_test']).value_counts())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Below code was derived with the help of ClaudeCode AI assistant to perform some diagnostics to check for data leakage and other potential issues with the model performance.*"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1. Check for data leakage\n",
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC 1: Data Leakage Check\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train size: {len(results['X_train_text'])}\")\n",
    "print(f\"Test size: {len(results['X_test_text'])}\")\n",
    "print(f\"Overlap: {len(set(results['X_train_text']) & set(results['X_test_text']))} reviews\")\n",
    "if len(set(results['X_train_text']) & set(results['X_test_text'])) > 0:\n",
    "    print(\"⚠️ WARNING: Train and test sets overlap!\")\n",
    "\n",
    "# 2. Cross-validation (more realistic)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC 2: Cross-Validation Scores\")\n",
    "print(\"=\"*60)\n",
    "cv_scores = cross_val_score(results['tfidf_model'], results['X_train_text'], results['y_train'], cv=5)\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "if cv_scores.mean() < 0.95:\n",
    "    print(\"✅ More realistic scores - model isn't just memorizing\")\n",
    "else:\n",
    "    print(\"⚠️ Still suspiciously high\")\n",
    "\n",
    "# 3. Dataset size and distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC 3: Dataset Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(bikerental_reviews_df['cleaned_review_text'])}\")\n",
    "print(f\"Classes: {len(set(results['y_train']))}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(pd.Series(results['y_train']).value_counts())\n",
    "print(f\"\\nAverage review length: {np.mean([len(r.split()) for r in results['cleaned_reviews_X']]):.1f} words\")\n",
    "\n",
    "# 4. Look at what model is using\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC 4: Most Important Features\")\n",
    "print(\"=\"*60)\n",
    "feature_names = results['tfidf_vectorizer'].get_feature_names_out()\n",
    "if hasattr(results['tfidf_model'], 'coef_'):\n",
    "    # For binary/multiclass logistic regression\n",
    "    for idx, class_name in enumerate(label_encoder.classes_):\n",
    "        top_features = np.argsort(results['tfidf_model'].coef_[idx])[-10:]\n",
    "        print(f\"\\nTop features for '{class_name}':\")\n",
    "        print([feature_names[i] for i in top_features])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Findings summary\n",
    "\n",
    "So far, the two vectorization techniques have been compared using Logistic Regression as the model. The TfidfVectorizer has shown a slight edge in accuracy over CountVectorizer. But still they show 100% accuracy which is suspiciously high for a real-world NLP task, indicating potential data leakage. The above some extra analysis diagnostics were performed to check for data leakage, cross-validation scores, dataset size and distribution, and important features used by the model. To address this, I am going to try check the uniquess of the reviews and resolve them."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TRIAL 1 -Remove duplicates BEFORE splitting\n",
    "unique_reviews_df_1 = bikerental_reviews_df.drop_duplicates(subset=['cleaned_review_text'], keep='first')\n",
    "print(f\"Original size: {len(bikerental_reviews_df)}\")\n",
    "print(f\"After removing duplicates: {len(unique_reviews_df_1)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TRIAL 2 - Try with the dupes removal on the original reviews_text column\n",
    "unique_reviews_df = bikerental_reviews_df.drop_duplicates(subset=['review_text'], keep='first')\n",
    "print(f\"Original size: {len(bikerental_reviews_df)}\")\n",
    "print(f\"After removing duplicates based on original review_text: {len(unique_reviews_df)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After carefully reviewing the data, we have to take only 300 unique reviews for our further analysis to avoid data leakage. So, we will proceed with the `unique_reviews_df` DataFrame for the next steps."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique_reviews_df['cleaned_reviews_v2'] = unique_reviews_df['review_text'].apply(clean_reviews)\n",
    "\n",
    "unique_reviews_df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "unique_review_comparison_results = compare_vectorizers_logreg(df=unique_reviews_df, text_col='cleaned_review_text', label_col='encoded_sentiment')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task-2 sentimental analysis"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Task\n",
    "Perform sentiment analysis on the `bike_rental_reviews.csv` dataset. This involves splitting the preprocessed and vectorized text data into training and testing sets, then training and evaluating both Logistic Regression and Naïve Bayes models. Additionally, prepare the cleaned text data for deep learning by tokenizing, creating word embeddings, and padding sequences, followed by building and evaluating an LSTM neural network. Finally, install the Hugging Face Transformers library, tokenize the cleaned text data for BERT, and then build and evaluate a pre-trained BERT model fine-tuned for sentiment classification."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = feature_X_arr\n",
    "y = bikerental_reviews_df['original_sentiment'].astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build and Evaluate Logistic Regression Model\n",
    "\n",
    "### Subtask:\n",
    "Train a Logistic Regression model on the training data and evaluate its performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "To train and evaluate a Logistic Regression model, I will import the necessary classes and functions, initialize the model, fit it to the training data, make predictions on the test data, and then calculate and print the required evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "# max_iter is set to a higher value to ensure convergence\n",
    "# solver='liblinear' is generally good for small datasets or when L1/L2 regularization is used\n",
    "log_reg_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "print(\"Training Logistic Regression model...\")\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "precision_log_reg = precision_score(y_test, y_pred_log_reg, average='weighted')\n",
    "recall_log_reg = recall_score(y_test, y_pred_log_reg, average='weighted')\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg, average='weighted')\n",
    "\n",
    "print(f\"\\n--- Logistic Regression Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_log_reg:.4f}\")\n",
    "print(f\"Precision (weighted): {precision_log_reg:.4f}\")\n",
    "print(f\"Recall (weighted): {recall_log_reg:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1_log_reg:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build and Evaluate Naïve Bayes Model\n",
    "\n",
    "### Subtask:\n",
    "Train a Naïve Bayes classifier on the training data and evaluate its performance using appropriate metrics.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Reasoning:\n",
    "To train and evaluate a Naïve Bayes model, I will import the necessary classes and functions, initialize the model, fit it to the training data, make predictions on the test data, and then calculate and print the required evaluation metrics."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "Implement the Naïve Bayes model training and evaluation as described in the instructions, including importing necessary libraries, initializing the model, fitting it to the training data, making predictions, and calculating evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB(fit_prior=True, class_prior=None)\n",
    "\n",
    "# Fit the model to the training data\n",
    "print(\"Training Naïve Bayes model...\")\n",
    "nb_model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb, average='weighted')\n",
    "recall_nb = recall_score(y_test, y_pred_nb, average='weighted')\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "\n",
    "print(f\"\\n--- Naïve Bayes Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
    "print(f\"Precision (weighted): {precision_nb:.4f}\")\n",
    "print(f\"Recall (weighted): {recall_nb:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1_nb:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare Data for Deep Learning Models (LSTM)\n",
    "\n",
    "### Subtask:\n",
    "Tokenize the cleaned text data for deep learning, create word embeddings, and pad sequences to a uniform length for LSTM input.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "To prepare the cleaned text data for deep learning models like LSTM, I will first import the necessary Keras utilities. Then, I'll initialize a Tokenizer to build a vocabulary from the cleaned reviews, convert these texts into numerical sequences, and finally pad these sequences to a uniform length suitable for neural network input.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize a Tokenizer\n",
    "# Set num_words to a suitable number based on your vocabulary size. Let's use 5000 as a starting point.\n",
    "# The vocab from CountVectorizer had 111 unique words, so 5000 is more than enough.\n",
    "# We will use the 'cleaned_review_text' column for this.\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<unk>')\n",
    "\n",
    "# Fit the tokenizer on the 'cleaned_review_text' column to build the vocabulary\n",
    "print(\"Fitting tokenizer on cleaned review text...\")\n",
    "tokenizer.fit_on_texts(bikerental_reviews_df['cleaned_review_text'])\n",
    "print(\"Tokenizer fitting complete.\")\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "print(\"Converting texts to sequences...\")\n",
    "sequences = tokenizer.texts_to_sequences(bikerental_reviews_df['cleaned_review_text'])\n",
    "print(\"Text to sequence conversion complete.\")\n",
    "\n",
    "# Determine the maximum sequence length\n",
    "max_sequence_length = max([len(x) for x in sequences])\n",
    "print(f\"Maximum sequence length: {max_sequence_length}\")\n",
    "\n",
    "# Pad the sequences to a uniform length\n",
    "# Use 'post' padding and truncation to maintain the beginning of the reviews\n",
    "print(\"Padding sequences...\")\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "print(\"Sequence padding complete.\")\n",
    "\n",
    "print(f\"Shape of padded sequences: {padded_sequences.shape}\")\n",
    "# Display the first 5 padded sequences\n",
    "print(\"\\nFirst 5 padded sequences:\")\n",
    "print(padded_sequences[:5])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "Now that the text data has been tokenized and padded, the next step in preparing data for deep learning models like LSTM is to prepare the target variable for model training. This involves encoding the categorical sentiment labels into a numerical format suitable for deep learning, such as one-hot encoding or label encoding, depending on the model's output layer.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encode the target variable (original_sentiment) to numerical values\n",
    "print(\"Encoding sentiment labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(bikerental_reviews_df['original_sentiment'])\n",
    "\n",
    "# Convert integer labels to one-hot encoded vectors for multi-class classification\n",
    "y_dl = to_categorical(y_encoded)\n",
    "print(\"Sentiment labels encoded and one-hot converted.\")\n",
    "\n",
    "print(f\"Shape of one-hot encoded labels (y_dl): {y_dl.shape}\")\n",
    "print(\"First 5 one-hot encoded labels:\")\n",
    "print(y_dl[:5])\n",
    "print(\"Original sentiment categories:\", label_encoder.classes_)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "The data has been preprocessed for deep learning models. Now, I need to split the padded sequences (features) and the one-hot encoded labels (target) into training and testing sets to prepare for building the LSTM model.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the padded sequences and one-hot encoded labels into training and testing sets\n",
    "# Use a test_size of 0.2 and random_state for reproducibility\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(padded_sequences, y_dl, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of X_train_dl: {X_train_dl.shape}\")\n",
    "print(f\"Shape of X_test_dl: {X_test_dl.shape}\")\n",
    "print(f\"Shape of y_train_dl: {y_train_dl.shape}\")\n",
    "print(f\"Shape of y_test_dl: {y_test_dl.shape}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build and Evaluate LSTM Model\n",
    "\n",
    "### Subtask:\n",
    "Construct and train an LSTM (Long Short-Term Memory) neural network for sentiment classification, then evaluate its performance.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "To construct and train the LSTM model, I will import the necessary Keras layers, define model parameters, build a Sequential model with Embedding, SpatialDropout1D, LSTM, and Dense layers, compile it, and then train and evaluate it using the prepared deep learning datasets.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "\n",
    "# 1. Define model parameters\n",
    "vocabulary_size = tokenizer.num_words\n",
    "embedding_dim = 128 # A common choice for embedding dimensions\n",
    "input_length = max_sequence_length\n",
    "num_sentiment_classes = y_dl.shape[1]\n",
    "\n",
    "print(f\"Vocabulary size: {vocabulary_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Input sequence length: {input_length}\")\n",
    "print(f\"Number of sentiment classes: {num_sentiment_classes}\")\n",
    "\n",
    "# 2. Build the LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=input_length),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(128),\n",
    "    Dense(num_sentiment_classes, activation='softmax')\n",
    "])\n",
    "print(\"LSTM model built.\")\n",
    "\n",
    "# 3. Compile the model\n",
    "print(\"Compiling LSTM model...\")\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"LSTM model compiled.\")\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "# 4. Train the LSTM model\n",
    "print(\"Training LSTM model...\")\n",
    "history = lstm_model.fit(\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    epochs=5, # Number of epochs can be tuned\n",
    "    batch_size=128, # Batch size can be tuned\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    verbose=1\n",
    ")\n",
    "print(\"LSTM model training complete.\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"Evaluating LSTM model performance on test set...\")\n",
    "loss, accuracy = lstm_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "\n",
    "print(f\"\\n--- LSTM Model Evaluation ---\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "The previous code produced a warning about the deprecated `input_length` argument in the `Embedding` layer. Removing this argument will resolve the warning as Keras can infer the input length from the input data.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "\n",
    "# 1. Define model parameters\n",
    "vocabulary_size = tokenizer.num_words\n",
    "embedding_dim = 128 # A common choice for embedding dimensions\n",
    "input_length = max_sequence_length\n",
    "num_sentiment_classes = y_dl.shape[1]\n",
    "\n",
    "print(f\"Vocabulary size: {vocabulary_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Input sequence length: {input_length}\")\n",
    "print(f\"Number of sentiment classes: {num_sentiment_classes}\")\n",
    "\n",
    "# 2. Build the LSTM model\n",
    "print(\"Building LSTM model...\")\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=vocabulary_size, output_dim=embedding_dim), # Removed input_length\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(128),\n",
    "    Dense(num_sentiment_classes, activation='softmax')\n",
    "])\n",
    "print(\"LSTM model built.\")\n",
    "\n",
    "# 3. Compile the model\n",
    "print(\"Compiling LSTM model...\")\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"LSTM model compiled.\")\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "# 4. Train the LSTM model\n",
    "print(\"Training LSTM model...\")\n",
    "history = lstm_model.fit(\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    epochs=5, # Number of epochs can be tuned\n",
    "    batch_size=128, # Batch size can be tuned\n",
    "    validation_data=(X_test_dl, y_test_dl),\n",
    "    verbose=1\n",
    ")\n",
    "print(\"LSTM model training complete.\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"Evaluating LSTM model performance on test set...\")\n",
    "loss, accuracy = lstm_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "\n",
    "print(f\"\\n--- LSTM Model Evaluation ---\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare Data for BERT Model\n",
    "\n",
    "### Subtask:\n",
    "Install the Hugging Face Transformers library and tokenize the cleaned text data for BERT."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "The next step is to install the Hugging Face Transformers library, which is necessary for working with BERT models.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install transformers"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Reasoning**:\n",
    "With the `transformers` library installed, I will now import the necessary BERT tokenizer and tokenize the `cleaned_review_text` column from the DataFrame. This prepares the text data into an input format suitable for BERT models.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Function to tokenize and encode text for BERT\n",
    "def tokenize_for_bert(text, tokenizer, max_len=128):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,      # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Return attention mask.\n",
    "                        return_tensors = 'pt',     # Return PyTorch tensors.\n",
    "                   )\n",
    "    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
    "\n",
    "print(\"Tokenizing and encoding text for BERT...\")\n",
    "# Apply the tokenizer to the 'cleaned_review_text' column\n",
    "bert_input_ids = []\n",
    "bert_attention_masks = []\n",
    "\n",
    "max_bert_len = 128 # Define a max length for BERT sequences\n",
    "\n",
    "for text in bikerental_reviews_df['cleaned_review_text']:\n",
    "    input_id, attention_mask = tokenize_for_bert(text, tokenizer_bert, max_bert_len)\n",
    "    bert_input_ids.append(input_id)\n",
    "    bert_attention_masks.append(attention_mask)\n",
    "\n",
    "# Convert the lists of tensors into single tensors\n",
    "bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
    "bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
    "\n",
    "print(\"Tokenization and encoding complete.\")\n",
    "print(f\"Shape of BERT input IDs: {bert_input_ids.shape}\")\n",
    "print(f\"Shape of BERT attention masks: {bert_attention_masks.shape}\")\n",
    "\n",
    "# Prepare the labels for BERT (using the previously encoded y_encoded)\n",
    "# Convert y_encoded to a PyTorch tensor\n",
    "labels_bert = torch.tensor(y_encoded)\n",
    "print(f\"Shape of BERT labels: {labels_bert.shape}\")"
   ]
  }
 ]
}
