{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dental X-Ray Denoising with Autoencoder\n",
    "\n",
    "Matthew Lucas  \n",
    "Unit 4 Incremental Capstone  \n",
    "Class 2509 TA\n",
    "\n",
    "**Objective:** Build an autoencoder to remove noise from dental X-ray images. The model will learn to reconstruct clean images from noisy versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Reproducibility\n",
    "# TODO: Set SEED to 42\n",
    "SEED = ___\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# TODO: Use np.load() to load 'DENTAL_1.NPZ'\n",
    "data = np.___('DENTAL_1.NPZ')\n",
    "\n",
    "# Extract arrays\n",
    "# TODO: Extract 'x_train', 'x_test', 'y_train', 'y_test' from the loaded data\n",
    "X_train_clean = data[___]\n",
    "X_test_clean = data[___]\n",
    "y_train = data[___]\n",
    "y_test = data[___]\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Training images: {X_train_clean.shape}\")\n",
    "print(f\"Test images: {X_test_clean.shape}\")\n",
    "print(f\"Training labels: {y_train.shape}\")\n",
    "print(f\"Test labels: {y_test.shape}\")\n",
    "\n",
    "# Check original pixel value range\n",
    "print(f\"\\nOriginal pixel value range:\")\n",
    "print(f\"Training: min={X_train_clean.min():.3f}, max={X_train_clean.max():.3f}\")\n",
    "print(f\"Test: min={X_test_clean.min():.3f}, max={X_test_clean.max():.3f}\")\n",
    "\n",
    "# Convert to float32 (data is already normalized to [0, 1] range)\n",
    "# Do NOT divide by 255 - the data is already normalized!\n",
    "# TODO: Convert X_train_clean and X_test_clean to float32\n",
    "X_train_clean = X_train_clean.astype(___)\n",
    "X_test_clean = X_test_clean.astype(___)\n",
    "\n",
    "print(f\"\\nAfter conversion to float32:\")\n",
    "print(f\"Training: min={X_train_clean.min():.3f}, max={X_train_clean.max():.3f}\")\n",
    "print(f\"Test: min={X_test_clean.min():.3f}, max={X_test_clean.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Gaussian Noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise to create noisy versions of the images\n",
    "# This simulates real-world noise in X-ray images\n",
    "# TODO: Set NOISE_FACTOR to 0.3 (controls the amount of noise)\n",
    "NOISE_FACTOR = ___\n",
    "\n",
    "def add_noise(images, noise_factor=NOISE_FACTOR):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to images.\n",
    "    \n",
    "    Args:\n",
    "        images: Clean images (normalized to [0, 1])\n",
    "        noise_factor: Standard deviation of the noise (relative to image range)\n",
    "    \n",
    "    Returns:\n",
    "        Noisy images\n",
    "    \"\"\"\n",
    "    # Generate noise with same shape as images\n",
    "    # TODO: Use np.random.normal() to generate noise\n",
    "    # Parameters: loc=0.0, scale=noise_factor, size=images.shape\n",
    "    noise = np.random.normal(loc=___, scale=___, size=___)\n",
    "    \n",
    "    # Add noise and clip to valid range [0, 1]\n",
    "    # TODO: Add noise to images and clip to [0.0, 1.0] using np.clip()\n",
    "    noisy_images = images + ___\n",
    "    noisy_images = np.clip(___, ___, ___)\n",
    "    \n",
    "    return noisy_images\n",
    "\n",
    "# Create noisy versions of training and test images\n",
    "# TODO: Call add_noise() for both training and test images\n",
    "X_train_noisy = add_noise(___, noise_factor=___)\n",
    "X_test_noisy = add_noise(___, noise_factor=___)\n",
    "\n",
    "print(f\"Created noisy images with noise factor: {NOISE_FACTOR}\")\n",
    "print(f\"Training noisy images shape: {X_train_noisy.shape}\")\n",
    "print(f\"Test noisy images shape: {X_test_noisy.shape}\")\n",
    "\n",
    "# Display sample images to see the noise\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i in range(4):\n",
    "    # Clean images (top row)\n",
    "    axes[0, i].imshow(X_train_clean[i])\n",
    "    axes[0, i].set_title('Clean')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Noisy images (bottom row)\n",
    "    axes[1, i].imshow(X_train_noisy[i])\n",
    "    axes[1, i].set_title('Noisy')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images: Clean (top) vs Noisy (bottom)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Autoencoder Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build autoencoder for image denoising\n",
    "# Input shape: (256, 256, 3) - RGB images\n",
    "\n",
    "# Encoder: Compresses the image to a lower-dimensional representation\n",
    "# TODO: Build the encoder with Conv2D and MaxPooling2D layers\n",
    "# Layer 1: Conv2D with 32 filters, (3,3) kernel, 'relu' activation, 'same' padding\n",
    "# Layer 2: MaxPooling2D with (2,2) pool size, 'same' padding\n",
    "# Layer 3: Conv2D with 64 filters, (3,3) kernel, 'relu' activation, 'same' padding\n",
    "# Layer 4: MaxPooling2D with (2,2) pool size, 'same' padding\n",
    "# Layer 5: Conv2D with 128 filters, (3,3) kernel, 'relu' activation, 'same' padding\n",
    "# Layer 6: MaxPooling2D with (2,2) pool size, 'same' padding\n",
    "encoder = models.Sequential([\n",
    "    layers.Input(shape=(256, 256, 3)),\n",
    "    layers.Conv2D(___, (___, ___), activation=___, padding=___),\n",
    "    layers.MaxPooling2D((___, ___), padding=___),  # 128x128\n",
    "    layers.Conv2D(___, (___, ___), activation=___, padding=___),\n",
    "    layers.MaxPooling2D((___, ___), padding=___),  # 64x64\n",
    "    layers.Conv2D(___, (___, ___), activation=___, padding=___),\n",
    "    layers.MaxPooling2D((___, ___), padding=___),  # 32x32\n",
    "])\n",
    "\n",
    "# Decoder: Reconstructs the image from the compressed representation\n",
    "# TODO: Build the decoder with Conv2DTranspose and Conv2D layers\n",
    "# Layer 1: Conv2DTranspose with 128 filters, (3,3) kernel, strides=2, 'relu' activation, 'same' padding\n",
    "# Layer 2: Conv2DTranspose with 64 filters, (3,3) kernel, strides=2, 'relu' activation, 'same' padding\n",
    "# Layer 3: Conv2DTranspose with 32 filters, (3,3) kernel, strides=2, 'relu' activation, 'same' padding\n",
    "# Layer 4: Conv2D with 3 filters, (3,3) kernel, 'sigmoid' activation, 'same' padding (output layer)\n",
    "decoder = models.Sequential([\n",
    "    layers.Conv2DTranspose(___, (___, ___), strides=___, activation=___, padding=___),  # 64x64\n",
    "    layers.Conv2DTranspose(___, (___, ___), strides=___, activation=___, padding=___),   # 128x128\n",
    "    layers.Conv2DTranspose(___, (___, ___), strides=___, activation=___, padding=___),  # 256x256\n",
    "    layers.Conv2D(___, (___, ___), activation=___, padding=___)  # Output: 256x256x3\n",
    "])\n",
    "\n",
    "# Combine encoder and decoder\n",
    "# TODO: Create the autoencoder by combining encoder and decoder\n",
    "autoencoder = models.Sequential([___, ___])\n",
    "\n",
    "# Compile the model\n",
    "# TODO: Compile with optimizer='adam', loss='mse', metrics=['mae']\n",
    "autoencoder.compile(\n",
    "    optimizer=___,\n",
    "    loss=___,  # Mean Squared Error for reconstruction\n",
    "    metrics=[___]  # Mean Absolute Error\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks\n",
    "# TODO: Create EarlyStopping callback with:\n",
    "# - monitor='val_loss'\n",
    "# - patience=10\n",
    "# - restore_best_weights=True\n",
    "# - verbose=1\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=___,\n",
    "        patience=___,\n",
    "        restore_best_weights=___,\n",
    "        verbose=___\n",
    "    ),\n",
    "    # TODO: Create ReduceLROnPlateau callback with:\n",
    "    # - monitor='val_loss'\n",
    "    # - factor=0.5\n",
    "    # - patience=5\n",
    "    # - min_lr=1e-7\n",
    "    # - verbose=1\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=___,\n",
    "        factor=___,\n",
    "        patience=___,\n",
    "        min_lr=___,\n",
    "        verbose=___\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the autoencoder\n",
    "# Input: noisy images, Target: clean images\n",
    "# The model learns to reconstruct clean images from noisy ones\n",
    "# TODO: Fill in model.fit() parameters:\n",
    "# - X_train_noisy (input: noisy images)\n",
    "# - X_train_clean (target: clean images)\n",
    "# - validation_data=(X_test_noisy, X_test_clean)\n",
    "# - epochs=50\n",
    "# - batch_size=8\n",
    "# - callbacks=callbacks\n",
    "# - verbose=1\n",
    "history = autoencoder.fit(\n",
    "    ___,  # Input: noisy images\n",
    "    ___,  # Target: clean images\n",
    "    validation_data=(___, ___),\n",
    "    epochs=___,\n",
    "    batch_size=___,\n",
    "    callbacks=___,\n",
    "    verbose=___\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# TODO: Use autoencoder.evaluate() on X_test_noisy and X_test_clean\n",
    "# Set verbose=0\n",
    "test_loss, test_mae = autoencoder.___(___, ___, verbose=___)\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n",
    "print(f\"Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "# Generate predictions (denoised images)\n",
    "# TODO: Use autoencoder.predict() on X_test_noisy\n",
    "# Set verbose=0\n",
    "denoised_images = autoencoder.___(___, verbose=___)\n",
    "\n",
    "print(f\"\\nDenoised images shape: {denoised_images.shape}\")\n",
    "print(f\"Denoised pixel range: [{denoised_images.min():.3f}, {denoised_images.max():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results: Compare noisy, denoised, and clean images\n",
    "n_samples = 8\n",
    "fig, axes = plt.subplots(3, n_samples, figsize=(16, 6))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Row 1: Noisy images (input)\n",
    "    axes[0, i].imshow(X_test_noisy[i])\n",
    "    axes[0, i].set_title('Noisy (Input)')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Denoised images (model output)\n",
    "    axes[1, i].imshow(denoised_images[i])\n",
    "    axes[1, i].set_title('Denoised (Output)')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: Clean images (ground truth)\n",
    "    axes[2, i].imshow(X_test_clean[i])\n",
    "    axes[2, i].set_title('Clean (Ground Truth)')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.suptitle('Denoising Results: Noisy → Denoised → Clean', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction error for each test image\n",
    "# TODO: Calculate MSE per image using np.mean() on (X_test_clean - denoised_images) ** 2\n",
    "# Use axis=(1, 2, 3) to average across height, width, and channels\n",
    "mse_per_image = np.mean((___ - ___) ** 2, axis=(___, ___, ___))\n",
    "\n",
    "# TODO: Calculate MAE per image using np.mean() on np.abs(X_test_clean - denoised_images)\n",
    "# Use axis=(1, 2, 3) to average across height, width, and channels\n",
    "mae_per_image = np.mean(np.abs(___ - ___), axis=(___, ___, ___))\n",
    "\n",
    "print(\"Reconstruction Error Statistics:\")\n",
    "print(f\"Mean MSE per image: {np.mean(mse_per_image):.6f}\")\n",
    "print(f\"Mean MAE per image: {np.mean(mae_per_image):.6f}\")\n",
    "print(f\"\\nBest reconstruction (lowest MSE): Image {np.argmin(mse_per_image)}\")\n",
    "print(f\"Worst reconstruction (highest MSE): Image {np.argmax(mse_per_image)}\")\n",
    "\n",
    "# Visualize best and worst reconstructions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Best reconstruction\n",
    "# TODO: Find the index of the best reconstruction using np.argmin() on mse_per_image\n",
    "best_idx = np.___(___)\n",
    "axes[0, 0].imshow(X_test_noisy[best_idx])\n",
    "axes[0, 0].set_title(f'Noisy (MSE: {mse_per_image[best_idx]:.6f})')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(denoised_images[best_idx])\n",
    "axes[0, 1].set_title('Denoised')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(X_test_clean[best_idx])\n",
    "axes[0, 2].set_title('Clean (Ground Truth)')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Worst reconstruction\n",
    "# TODO: Find the index of the worst reconstruction using np.argmax() on mse_per_image\n",
    "worst_idx = np.___(___)\n",
    "axes[1, 0].imshow(X_test_noisy[worst_idx])\n",
    "axes[1, 0].set_title(f'Noisy (MSE: {mse_per_image[worst_idx]:.6f})')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(denoised_images[worst_idx])\n",
    "axes[1, 1].set_title('Denoised')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(X_test_clean[worst_idx])\n",
    "axes[1, 2].set_title('Clean (Ground Truth)')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Best (top) and Worst (bottom) Reconstructions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "# TODO: Plot history.history['loss'] and history.history['val_loss']\n",
    "axes[0].plot(history.history[___], label='Training Loss')\n",
    "axes[0].plot(history.history[___], label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Model Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# MAE plot\n",
    "# TODO: Plot history.history['mae'] and history.history['val_mae']\n",
    "axes[1].plot(history.history[___], label='Training MAE')\n",
    "axes[1].plot(history.history[___], label='Validation MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Mean Absolute Error')\n",
    "axes[1].set_title('Model MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to Consider\n",
    "\n",
    "Reflect on what you've learned and explore further:\n",
    "\n",
    "### Understanding the Model\n",
    "\n",
    "1. **How does an autoencoder work?** Explain the difference between the encoder and decoder components. What happens to the image dimensions as it passes through the encoder? How does the decoder reconstruct the image?\n",
    "\n",
    "2. **Why use MSE (Mean Squared Error) as the loss function?** What does MSE measure, and why is it appropriate for image reconstruction tasks? How would the results differ if you used a different loss function?\n",
    "\n",
    "3. **What role does the bottleneck play?** The encoder compresses the image from 256×256×3 down to 32×32×128. What information is preserved in this compressed representation? What information might be lost?\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "4. **Analyze the reconstruction quality:** Compare the best and worst reconstructions. What characteristics make some images easier to denoise than others? Are there patterns in the images that the model struggles with?\n",
    "\n",
    "5. **Noise factor impact:** How would changing the `NOISE_FACTOR` affect the model's performance? Try different values (e.g., 0.1, 0.5, 0.7) and observe how the denoising quality changes. What happens when the noise is too strong?\n",
    "\n",
    "6. **Training observations:** Look at the training history plots. Did the model converge? Were there signs of overfitting or underfitting? How did the validation loss compare to training loss?\n",
    "\n",
    "### Experimentation Ideas\n",
    "\n",
    "7. **Architecture modifications:** Try modifying the autoencoder architecture:\n",
    "   - Add more layers to the encoder/decoder\n",
    "   - Change the number of filters in each layer\n",
    "   - Add dropout layers to prevent overfitting\n",
    "   - Experiment with different activation functions\n",
    "\n",
    "8. **Different noise types:** Instead of Gaussian noise, try:\n",
    "   - Salt-and-pepper noise\n",
    "   - Poisson noise (common in medical imaging)\n",
    "   - Motion blur\n",
    "   - How does the model perform with different noise types?\n",
    "\n",
    "9. **Loss function alternatives:** Experiment with different loss functions:\n",
    "   - Perceptual loss (using a pre-trained network)\n",
    "   - SSIM (Structural Similarity Index)\n",
    "   - Combination of MSE and MAE\n",
    "   - How do these affect reconstruction quality?\n",
    "\n",
    "10. **Real-world applications:** Where else could autoencoders be useful?\n",
    "    - Image compression\n",
    "    - Anomaly detection\n",
    "    - Feature extraction\n",
    "    - Data augmentation\n",
    "    - What other medical imaging tasks could benefit from denoising?\n",
    "\n",
    "### Further Exploration\n",
    "\n",
    "11. **Compare with other methods:** Research traditional image denoising techniques (e.g., Gaussian blur, median filtering, bilateral filtering). How do they compare to the autoencoder approach? What are the advantages and disadvantages of each?\n",
    "\n",
    "12. **Variational Autoencoders (VAEs):** Research VAEs and how they differ from standard autoencoders. What additional capabilities do they provide? When would you choose a VAE over a standard autoencoder?\n",
    "\n",
    "13. **Transfer learning:** Could you use a pre-trained encoder (e.g., from ImageNet) and only train the decoder? How would this affect training time and performance?\n",
    "\n",
    "### Critical Thinking\n",
    "\n",
    "14. **Limitations:** What are the limitations of this autoencoder approach? When might it fail? Are there scenarios where denoising might remove important details from medical images?\n",
    "\n",
    "15. **Ethical considerations:** In medical imaging, image quality can affect diagnosis. What are the ethical implications of using AI to denoise medical images? Should denoised images be clearly labeled as processed?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
